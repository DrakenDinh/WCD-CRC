{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeGAN \n",
    "\n",
    "## Time-series Generative Adversarial Networks\n",
    "\n",
    "- Paper: Jinsung Yoon, Daniel Jarrett, Mihaela van der Schaar, \"Time-series Generative Adversarial Networks,\" Neural Information Processing Systems (NeurIPS), 2019.\n",
    "\n",
    "- Paper link: https://papers.nips.cc/paper/8789-time-series-generative-adversarial-networks\n",
    "\n",
    "- Code author: Jinsung Yoon (jsyoon0823@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary packages and functions call\n",
    "\n",
    "- timegan: Synthetic time-series data generation module\n",
    "- data_loading: 2 real datasets and 1 synthetic datasets loading and preprocessing\n",
    "- metrics: \n",
    "    - discriminative_metrics: classify real data from synthetic data\n",
    "    - predictive_metrics: train on synthetic, test on real\n",
    "    - visualization: PCA and tSNE analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Necessary packages\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1. TimeGAN model\n",
    "from timegan import timegan\n",
    "# 2. Data loading\n",
    "from data_loading import patient_data_loading, sine_data_generation\n",
    "# 3. Metrics\n",
    "from metrics.discriminative_metrics import discriminative_score_metrics\n",
    "from metrics.predictive_metrics import predictive_score_metrics\n",
    "from metrics.visualization_metrics import visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data.\n",
    "\n",
    "- data_name: stock, energy, or sine\n",
    "- seq_len: sequence length of the time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data loading\n",
    "data_name = 'patient_HighTrain'\n",
    "seq_len = 88\n",
    "\n",
    "if data_name == 'patient_HighTrain':\n",
    "   folder_path = 'data/patient_HighTrain' \n",
    "   ori_data = patient_data_loading(folder_path, seq_len)\n",
    "elif data_name == 'sine':\n",
    "  # Set number of samples and its dimensions\n",
    "  no, dim = 10000, 5\n",
    "  ori_data = sine_data_generation(no, seq_len, dim)\n",
    "\n",
    "print('Number of sequences:', len(ori_data))\n",
    "print('Each sequence shape:', ori_data[0].shape)    \n",
    "print(data_name + ' dataset is ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set network parameters\n",
    "\n",
    "TimeGAN network parameters should be optimized for different datasets.\n",
    "\n",
    "- module: gru, lstm, or lstmLN\n",
    "- hidden_dim: hidden dimensions\n",
    "- num_layer: number of layers\n",
    "- iteration: number of training iterations\n",
    "- batch_size: the number of samples in each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Newtork parameters\n",
    "parameters = dict()\n",
    "\n",
    "parameters['module'] = 'gru' \n",
    "parameters['hidden_dim'] = 24\n",
    "parameters['num_layer'] = 3\n",
    "parameters['iterations'] = 5000\n",
    "parameters['batch_size'] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run TimeGAN for synthetic time-series data generation\n",
    "\n",
    "TimeGAN uses the original data and network parameters to return the generated synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run TimeGAN\n",
    "generated_data = timegan(ori_data, parameters)   \n",
    "print('Finish Synthetic Data Generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 1. Discriminative score\n",
    "\n",
    "To evaluate the classification accuracy between original and synthetic data using post-hoc RNN network. The output is |classification accuracy - 0.5|.\n",
    "\n",
    "- metric_iteration: the number of iterations for metric computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_iteration = 5\n",
    "\n",
    "discriminative_score = list()\n",
    "for _ in range(metric_iteration):\n",
    "  temp_disc = discriminative_score_metrics(ori_data, generated_data)\n",
    "  discriminative_score.append(temp_disc)\n",
    "\n",
    "print('Discriminative score: ' + str(np.round(np.mean(discriminative_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 2. Predictive score\n",
    "\n",
    "To evaluate the prediction performance on train on synthetic, test on real setting. More specifically, we use Post-hoc RNN architecture to predict one-step ahead and report the performance in terms of MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_score = list()\n",
    "for tt in range(metric_iteration):\n",
    "  temp_pred = predictive_score_metrics(ori_data, generated_data)\n",
    "  predictive_score.append(temp_pred)   \n",
    "    \n",
    "print('Predictive score: ' + str(np.round(np.mean(predictive_score), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 3. Visualization\n",
    "\n",
    "We visualize the original and synthetic data distributions using PCA and tSNE analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization(ori_data, generated_data, 'pca')\n",
    "visualization(ori_data, generated_data, 'tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save generated data and limit the amount of generated data saved to the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from timegan import timegan  # or the appropriate import path in your project\n",
    "\n",
    "# Folder containing the original Excel files\n",
    "input_folder = r'C:\\your_path\\data\\patient_HighTrain'\n",
    "\n",
    "# Folder to save the generated results\n",
    "save_folder = r'C:\\your_path\\HR_Train_107_TimeGAN_HighRisk'\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "# Get a list of all .xlsx files\n",
    "excel_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.xlsx')]\n",
    "\n",
    "for file in excel_files:\n",
    "    original_filename = os.path.splitext(file)[0]\n",
    "    file_path = os.path.join(input_folder, file)\n",
    "\n",
    "    # Limit to 39 generated samples instead of using all TimeGAN-generated data.\n",
    "    # Afterward, copy the original data to obtain HR Ã— 39 samples.\n",
    "    generated_data = generated_data[:39]\n",
    "\n",
    "    # Save each generated sample to a separate Excel file, including column headers\n",
    "    for idx, sample in enumerate(generated_data, start=1):\n",
    "        df = pd.DataFrame(\n",
    "            sample,\n",
    "            columns=['Time', 'Brachial Data', 'Carotid Diameter', 'blood velocity']\n",
    "        )\n",
    "        out_name = f\"{original_filename}_{idx}.xlsx\"\n",
    "        out_path = os.path.join(save_folder, out_name)\n",
    "        df.to_excel(out_path, index=False)\n",
    "\n",
    "    print(\n",
    "        f\"{len(generated_data)} files have been saved from \"\n",
    "        f\"`{original_filename}` to `{save_folder}`\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "print(f\"\\nTotal time taken for the entire process: {end_time - start_time:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
