{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c9266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Add, UpSampling1D, LSTM, Dense, Dropout, Flatten, Bidirectional, BatchNormalization, LayerNormalization, Activation, Attention, MultiHeadAttention \n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from sklearn.metrics import r2_score, roc_curve, auc\n",
    "import time\n",
    "from keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc(\"font\",family = \"Malgun Gothic\")\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import BinaryFocalCrossentropy\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score\n",
    "import seaborn as sns\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a95b0-1fa7-43d2-9dd0-46fc93415f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix_rowwise(y_true, y_pred, class_names=None, figsize=(6,6), cmap=\"Blues\", title=None):\n",
    "    \"\"\"\n",
    "    Vẽ confusion matrix row-wise normalized với counts + % trên cùng một ô.\n",
    "    \"\"\"\n",
    "    # Tính CM raw counts\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "    \n",
    "    # Row-wise normalized (%) = mỗi hàng cộng 100%\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Tạo annot string \"count (percent%)\"\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annot[i,j] = f\"{cm[i,j]} ({cm_norm[i,j]:.1f}%)\"\n",
    "    \n",
    "    # Vẽ heatmap\n",
    "    plt.figure(figsize=figsize, dpi=120)\n",
    "    sns.heatmap(cm_norm, annot=annot, fmt=\"\", cmap=cmap, xticklabels=class_names,\n",
    "                yticklabels=class_names, linewidths=0.8, linecolor='gray', square=True)\n",
    "    \n",
    "    # Trục và title\n",
    "    plt.ylabel(\"True label\", fontsize=12, fontweight='bold')\n",
    "    plt.xlabel(\"Predicted label\", fontsize=12, fontweight='bold')\n",
    "    if title is None:\n",
    "        title = \"Confusion Matrix (Counts + Row-wise %)\"\n",
    "    plt.title(title, fontsize=14, fontweight='bold', pad=15)\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right', fontsize=11)\n",
    "    plt.yticks(rotation=0, fontsize=11)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    # Accuracy từ raw counts\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    print(f\"Accuracy from CM: {accuracy:.4f}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm, cm_norm, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aafcc1",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92d554",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = np.load(r'C:/your_training_dataset.npy',allow_pickle=True)\n",
    "\n",
    "print(\"train_dataset:\", train_dataset)\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b298a12-ae9a-41b2-849f-a22416876499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset = np.load(r'C:/your_testing_dataset.npy',allow_pickle=True)\n",
    "\n",
    "print(\"test_dataset:\", test_dataset)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1862547",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d7fcb5",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.load(r'C:/your_training_Labels.npy',allow_pickle=True)\n",
    "\n",
    "print(\"train_label:\", train_label)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d53ea8-6272-4a24-9395-8d92ffbfe34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.load(r'C:/your_testing_Labels.npy',allow_pickle=True)\n",
    "\n",
    "print(\"test_label:\", test_label)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc8333",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df357489-c4cb-4788-b443-9eaa4feab97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Checks (A) -------------------------------------------\n",
    "def check_data_distribution(y, set_name):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    print(f\"\\n{set_name} Class Distribution:\")\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"Class {cls}: {count} samples ({count/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Check original data distributions\n",
    "check_data_distribution(train_label, \"Raw Training\")\n",
    "check_data_distribution(test_label, \"Raw Testing\")\n",
    "\n",
    "# Check data leakage\n",
    "common_samples = set(map(tuple, train_dataset.reshape(train_dataset.shape[0], -1))) & \\\n",
    "                 set(map(tuple, test_dataset.reshape(test_dataset.shape[0], -1)))\n",
    "print(f\"\\nCommon samples between train and test: {len(common_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ea7d6-fdb2-46f1-b532-24b0bb17c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "#X_test = test_dataset\n",
    "#y_test = to_categorical(test_label, num_classes=2)\n",
    "\n",
    "# Fix all random seeds\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.config.threading.set_inter_op_parallelism_threads(1)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(1)\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "]\n",
    "y_test = test_label.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e0a8d4-e644-4446-997a-44907475f540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_names = ['Low CVD Risk', 'High CVD Risk']\n",
    "# Lists to store metrics\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "test_accuracies = []\n",
    "test_losses = []\n",
    "histories = []\n",
    "\n",
    "# ======================== Training Loop ==========================\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset, train_label), start=1):\n",
    "    print(f\"Fold {fold}/{n_splits}\")\n",
    "\n",
    "    X_train_fold, X_val_fold = train_dataset[train_idx], train_dataset[val_idx]\n",
    "    y_train_fold, y_val_fold = train_label[train_idx].reshape(-1), train_label[val_idx].reshape(-1)\n",
    "\n",
    "    check_data_distribution(y_train_fold, f\"Fold {fold} Training\")\n",
    "    check_data_distribution(y_val_fold, f\"Fold {fold} Validation\")\n",
    "\n",
    "    # ======================== Build Model ==========================\n",
    "    input_layer = Input(shape=(128, 3))\n",
    "    conv1 = Conv1D(64, kernel_size=3, kernel_regularizer=l2(0.001),\n",
    "                   kernel_initializer=tf.keras.initializers.glorot_uniform(seed=SEED))(input_layer)\n",
    "    ln1 = LayerNormalization()(conv1)\n",
    "    act1 = Activation('elu')(ln1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(act1)\n",
    "\n",
    "    conv2 = Conv1D(32, kernel_size=1, activation='elu')(pool1)\n",
    "    ln2 = LayerNormalization()(conv2)\n",
    "    act2 = Activation('elu')(ln2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(act2)\n",
    "    drop0 = Dropout(0.3)(pool2)\n",
    "\n",
    "    lstm1 = LSTM(32, activation='tanh', return_sequences=True)(drop0)\n",
    "    drop1 = Dropout(0.2)(lstm1)\n",
    "    lstm2 = LSTM(16, activation='tanh')(drop1)\n",
    "    drop2 = Dropout(0.2)(lstm2)\n",
    "    \n",
    "    flatten = Flatten()(drop2)\n",
    "    dense = Dense(16, activation='elu')(flatten)\n",
    "    output_layer = Dense(1, activation='sigmoid')(dense)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.summary()\n",
    "\n",
    "    # ======================== Compile with Focal Loss ==========================\n",
    "    focal_loss = BinaryFocalCrossentropy(alpha=0.80, gamma=2.0)\n",
    "    model.compile(loss=focal_loss, optimizer=Adamax(learning_rate=0.0005), metrics=['accuracy'])\n",
    "\n",
    "    # ======================== Train ==========================\n",
    "    start_time = time.time()\n",
    "    hist = model.fit(\n",
    "        X_train_fold, y_train_fold,\n",
    "        batch_size=128,\n",
    "        epochs=100,\n",
    "        validation_data=(X_val_fold, y_val_fold),\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    histories.append(hist.history)\n",
    "    end_time = time.time()\n",
    "\n",
    "    # ======================== Evaluate ==========================\n",
    "    val_loss, val_acc = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(test_dataset, y_test, verbose=0)\n",
    "    val_losses.append(val_loss); val_accuracies.append(val_acc)\n",
    "    test_losses.append(test_loss); test_accuracies.append(test_acc)\n",
    "\n",
    "    # ======================== Plots ==========================\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(hist.history['loss'], c='b')\n",
    "    plt.plot(hist.history['val_loss'], '-.', c='r')\n",
    "    plt.title(f'Fold {fold} Loss'); plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(hist.history['accuracy'], c='b')\n",
    "    plt.plot(hist.history['val_accuracy'], '-.', c='r')\n",
    "    plt.title(f'Fold {fold} Accuracy'); plt.ylabel('Accuracy'); plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f} | Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f} | Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Training Time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "    # ======================== Confusion Matrix + AUC ==========================\n",
    "    # Validation\n",
    "    y_val_prob = model.predict(X_val_fold).ravel()\n",
    "    y_val_pred = (y_val_prob > 0.5).astype(int)\n",
    "    plot_confusion_matrix_rowwise(y_val_fold, y_val_pred, class_names=class_names, \n",
    "                                  title=f\"Fold {fold} Validation CM\")\n",
    "    print(f\"Validation AUC: {roc_auc_score(y_val_fold, y_val_prob):.4f}\")\n",
    "    \n",
    "    # Test\n",
    "    y_test_prob = model.predict(test_dataset).ravel()\n",
    "    y_test_pred = (y_test_prob > 0.5).astype(int)\n",
    "    plot_confusion_matrix_rowwise(y_test, y_test_pred, class_names=class_names, \n",
    "                                  title=f\"Fold {fold} Test CM\")\n",
    "    print(f\"Test AUC: {roc_auc_score(y_test, y_test_prob):.4f}\")\n",
    "\n",
    "\n",
    "# ======================== Final CV Metrics ==========================\n",
    "print(\"\\n\\nFinal Cross-Validation Results:\")\n",
    "print(f\"Validation Loss: {np.mean(val_losses):.4f} ± {np.std(val_losses):.4f}\")\n",
    "print(f\"Validation Accuracy: {np.mean(val_accuracies):.4f} ± {np.std(val_accuracies):.4f}\")\n",
    "print(f\"Test Loss: {np.mean(test_losses):.4f} ± {np.std(test_losses):.4f}\")\n",
    "print(f\"Test Accuracy: {np.mean(test_accuracies):.4f} ± {np.std(test_accuracies):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32863c1a-586c-44cf-8cea-cb84fc7e2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ----------------- K-fold ROC storage -----------------\n",
    "y_test_probs_all = []  # lưu xác suất class 1 (High Risk)\n",
    "y_test_labels = y_test if y_test.ndim == 1 else y_test.reshape(-1)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_dataset, train_label), start=1):\n",
    "    \n",
    "    # ... training như code bạn đã có ...\n",
    "    \n",
    "    # Dự đoán xác suất trên test set\n",
    "    y_test_pred_prob = model.predict(X_test)  # shape (n_samples, 1)\n",
    "    y_test_probs_all.append(y_test_pred_prob.flatten())  # sigmoid -> chỉ 1 output\n",
    "\n",
    "# ----------------- Tính mean ROC và CI -----------------\n",
    "all_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "for y_pred_high in y_test_probs_all:\n",
    "    fpr, tpr, _ = roc_curve(y_test_labels, y_pred_high)\n",
    "    tpr_interp = np.interp(all_fpr, fpr, tpr)\n",
    "    tpr_interp[0] = 0.0\n",
    "    tprs.append(tpr_interp)\n",
    "\n",
    "tprs = np.array(tprs)\n",
    "mean_tpr = tprs.mean(axis=0)\n",
    "std_tpr = tprs.std(axis=0)\n",
    "roc_auc_mean = auc(all_fpr, mean_tpr)\n",
    "tpr_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tpr_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "# ----------------- Vẽ ROC với uncertainty -----------------\n",
    "plt.figure(figsize=(8,6), dpi=120)\n",
    "plt.fill_between(all_fpr, tpr_lower, tpr_upper, color='darkorange', alpha=0.2, label='±1 std. dev.')\n",
    "plt.plot(all_fpr, mean_tpr, color='darkorange', lw=3, label=f'Mean ROC (AUC={roc_auc_mean:.3f})')\n",
    "plt.plot([0,1], [0,1], color='gray', lw=1, linestyle='--', label='Random Classifier')\n",
    "\n",
    "plt.title('Test ROC Curve with Uncertainty (k-fold)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('False Positive Rate', fontsize=12)\n",
    "plt.ylabel('True Positive Rate', fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.legend(loc='lower right', frameon=True, facecolor='white', edgecolor='gray')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95003d-9e4d-47c1-986f-27c850cdc0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_dataset\n",
    "# ------------------- Labels (không cần one-hot) -------------------\n",
    "y_train_all = train_label.reshape(-1)   # giữ dạng 0/1\n",
    "\n",
    "# ------------------- Build final model -------------------\n",
    "input_layer = Input(shape=(128, 3))\n",
    "\n",
    "# Encoder Block\n",
    "conv1 = Conv1D(64, kernel_size=3, kernel_regularizer=l2(0.001),\n",
    "               kernel_initializer=tf.keras.initializers.glorot_uniform(seed=SEED))(input_layer)\n",
    "ln1 = LayerNormalization()(conv1)\n",
    "act1 = Activation('elu')(ln1)\n",
    "pool1 = MaxPooling1D(pool_size=2)(act1)\n",
    "\n",
    "conv2 = Conv1D(32, kernel_size=1, activation='elu')(pool1)\n",
    "ln2 = LayerNormalization()(conv2)\n",
    "act2 = Activation('elu')(ln2)\n",
    "pool2 = MaxPooling1D(pool_size=2)(act2)\n",
    "drop0 = Dropout(0.3)(pool2)\n",
    "\n",
    "# LSTM Block\n",
    "lstm1 = LSTM(32, activation='tanh', return_sequences=True)(drop0)\n",
    "drop1 = Dropout(0.2)(lstm1)\n",
    "lstm2 = LSTM(16, activation='tanh')(drop1)\n",
    "drop2 = Dropout(0.2)(lstm2)\n",
    "\n",
    "# Output\n",
    "flatten = Flatten(name=\"flatten_final\")(drop2)\n",
    "dense = Dense(16, activation='elu')(flatten)\n",
    "output_layer = Dense(1, activation='sigmoid')(dense)   # sigmoid cho binary\n",
    "\n",
    "model_final = Model(inputs=input_layer, outputs=output_layer)\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572eef4d-f6a1-4418-b6a4-977d22c8f57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- Compile với Focal Loss -------------------\n",
    "focal_loss = BinaryFocalCrossentropy(alpha=0.8, gamma=2.0)  # gamma có thể tune\n",
    "model_final.compile(loss=focal_loss,\n",
    "                   optimizer=Adamax(learning_rate=0.0005),\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "# ------------------- Train final model -------------------\n",
    "start_time = time.time()\n",
    "hist_final = model_final.fit(train_dataset, y_train_all,\n",
    "                            batch_size=128,\n",
    "                            epochs=100,\n",
    "                            shuffle=True,\n",
    "                            verbose=1)\n",
    "end_time = time.time()\n",
    "print(f\"\\nFinal Model Training Time: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c57677-3a89-4dcc-9e4e-6b45e9e8a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- Plot Training Curves -------------------\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(hist_final.history['loss'], c='b', label='Training Loss')\n",
    "plt.title('Final Model Training Loss'); plt.ylabel('Loss'); plt.xlabel('Epoch')\n",
    "plt.grid(linestyle='--'); plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(hist_final.history['accuracy'], c='g', label='Training Accuracy')\n",
    "plt.title('Final Model Training Accuracy'); plt.ylabel('Accuracy'); plt.xlabel('Epoch')\n",
    "plt.grid(linestyle='--'); plt.legend()\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# ------------------- Evaluate on Test -------------------\n",
    "score = model_final.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f8802-b7d4-462a-8a5f-e3912c841ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ------------------- ROC Curve -------------------\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_pred_prob = model_final.predict(X_test).flatten()  # shape (n_samples,)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8,6), dpi=120)\n",
    "plt.fill_between(fpr, tpr, alpha=0.2, color='darkorange')\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=3, label=f'ROC Curve (AUC={roc_auc:.3f})')\n",
    "plt.plot([0,1], [0,1], color='gray', lw=1, linestyle='--', label='Random Classifier')\n",
    "plt.title('Receiver Operating Characteristic (ROC)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right'); plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf8698-d238-4653-a821-04fad679f681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Tên lớp\n",
    "class_names = ['Low CVD Risk', 'High CVD Risk']\n",
    "\n",
    "# ==================== Hàm vẽ CM row-wise ====================\n",
    "def plot_confusion_matrix_rowwise(y_true, y_pred, class_names=None, figsize=(6,6), cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    Vẽ confusion matrix với counts + normalized 0-1 (row-wise) trong cùng 1 ô.\n",
    "    \"\"\"\n",
    "    # Tính confusion matrix raw counts\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=np.arange(len(class_names)))\n",
    "    \n",
    "    # Normalize row-wise\n",
    "    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    # Tạo annot string \"count (norm)\"\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            annot[i,j] = f\"{cm[i,j]} ({cm_norm[i,j]:.2f})\"\n",
    "    \n",
    "    # Vẽ heatmap\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(cm_norm, annot=annot, fmt=\"\", cmap=cmap,\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.title(\"Confusion Matrix (Counts + Row-wise%)\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Accuracy từ raw counts\n",
    "    accuracy = np.trace(cm) / np.sum(cm)\n",
    "    print(f\"Accuracy from CM: {accuracy:.4f}\")\n",
    "    \n",
    "    return cm, cm_norm, accuracy\n",
    "\n",
    "# ==================== Tính nhãn dự đoán ====================\n",
    "y_true = y_test.reshape(-1)\n",
    "y_pred_prob = model_final.predict(X_test).flatten()\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# ==================== Vẽ CM ====================\n",
    "cm, cm_norm, acc = plot_confusion_matrix_rowwise(y_true, y_pred, class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128526ec-4292-46fb-98ec-3e8063d89826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Đặt font mặc định (Arial, fallback sang DejaVu Sans nếu không có)\n",
    "matplotlib.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# --- Trích xuất feature từ model ---\n",
    "# Tìm layer Flatten cuối cùng (tự động)\n",
    "flatten_layers = [layer.name for layer in model_final.layers if \"flatten\" in layer.name]\n",
    "last_flatten = flatten_layers[-1]  # lấy flatten cuối\n",
    "intermediate_layer_model = Model(\n",
    "    inputs=model_final.input,\n",
    "    outputs=model_final.get_layer(last_flatten).output\n",
    ")\n",
    "\n",
    "# Trích xuất features\n",
    "features_before = train_dataset.reshape(train_dataset.shape[0], -1)  # dữ liệu gốc (chưa học)\n",
    "features_after = intermediate_layer_model.predict(train_dataset, verbose=0)  # feature sau khi học\n",
    "\n",
    "# Convert nhãn về numpy\n",
    "y_train_labels = np.array(train_label).astype(int)\n",
    "\n",
    "\n",
    "# --- Hàm vẽ t-SNE ---\n",
    "def plot_tsne(features, labels, title=\"t-SNE Visualization\"):\n",
    "    tsne = TSNE(\n",
    "        n_components=2,\n",
    "        random_state=42,\n",
    "        perplexity=30,\n",
    "        max_iter=1000,\n",
    "        learning_rate=\"auto\",\n",
    "        init=\"pca\"\n",
    "    )\n",
    "    reduced = tsne.fit_transform(features)\n",
    "\n",
    "    # Gán màu cố định cho từng class\n",
    "    colors = {0: \"#d62728\",  # đỏ cho High risk\n",
    "              1: \"#1f77b4\"}  # xanh cho Low risk\n",
    "    class_names = {0: \"Low CVD Risk\", 1: \"High CVD Risk\"}\n",
    "\n",
    "    plt.figure(figsize=(8, 6), dpi=120)\n",
    "    for label in sorted(set(labels)):\n",
    "        idx = labels == label\n",
    "        plt.scatter(\n",
    "            reduced[idx, 0],\n",
    "            reduced[idx, 1],\n",
    "            c=colors[label],\n",
    "            label=class_names[label],\n",
    "            alpha=0.75,\n",
    "            s=60,\n",
    "            edgecolors=\"k\",   # viền đen mỏng\n",
    "            linewidth=0.5\n",
    "        )\n",
    "\n",
    "    # Thiết kế chuyên nghiệp\n",
    "    plt.title(title, fontsize=14, fontweight=\"bold\", pad=15)\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.legend(frameon=True, facecolor=\"white\", framealpha=0.9, edgecolor=\"gray\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Vẽ ---\n",
    "plot_tsne(features_before, y_train_labels, \"t-SNE Before Training (Final Model)\")\n",
    "plot_tsne(features_after, y_train_labels, \"t-SNE After Training (Final Model)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
